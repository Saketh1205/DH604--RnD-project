# DH604--RnD-project

This project explores interpretable machine learning techniques across two domains: time series classification and medical image analysis. It compares state-of-the-art time series classifiers such as kNN, RSF, ROCKET, RISE, and BOSS, and evaluates the performance of frequency-domain features (DFT, DWT) on UCR datasets. Additionally, it demonstrates how SHAP (SHapley Additive exPlanations) can be used to explain model predictions.

In the second part, SHAP is applied to image data. First, explanations are visualized on the ImageNet dataset using pre-trained models. Finally, SHAP is applied to a Brain MRI classification model to identify critical regions contributing to model decisions, emphasizing the importance of interpretability in medical AI applications.
